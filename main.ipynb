{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imUsingColab = False\n",
    "shouldDownload = True # Set this to False after the first run to avoid redownloading the dataset\n",
    "if shouldDownload:\n",
    "  if imUsingColab:\n",
    "    # Generate the .env file within the colab environment programatically\n",
    "    file = open('.env','w') \n",
    "    file.write('KAGGLE_USERNAME=') # Populate this with your KAGGLE_USERNAME DO NOT COMMIT!!\n",
    "    file.write('\\nKAGGLE_KEY=') # Populate this with your KAGGLE api Key DO NOT COMMIT!!\n",
    "    file.close()\n",
    "    # Fetch the downloadData dependency \n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve (\"https://raw.githubusercontent.com/lihaojin/Movie_Data_Analysis/master/downloadData.py\", \"downloadData.py\")\n",
    "\n",
    "  import downloadData\n",
    "  downloadData.download(imUsingColab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run datasets.py\n",
    "%run functions.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math, nltk, warnings\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mergeData()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_keywords = set()\n",
    "for list_keywords in df['keywords'].str.split('|').values:\n",
    "    if isinstance(list_keywords, float): continue  # only happen if list_keywords = NaN\n",
    "    set_keywords = set_keywords.union(list_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_occurences, dum = count_word(df, 'keywords', set_keywords)\n",
    "keyword_occurences[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genres'] = df['genres'].astype(str)\n",
    "genre_labels = set()\n",
    "for s in df['genres'].str.split('|').values:\n",
    "    genre_labels = genre_labels.union(set(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_occurences, dum = count_word(df, 'genres', genre_labels)\n",
    "keyword_occurences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doubled_entries = df_initial[df_initial.duplicated()]\n",
    "doubled_entries = df[df.movieId.duplicated()]\n",
    "doubled_entries.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_var_duplicates = ['title', 'year', 'directors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_duplicates = df_temp['title'].map(df_temp['title'].value_counts() > 1)\n",
    "print(\"Nb. of duplicate entries: {}\".format(\n",
    "    len(df_temp[list_duplicates][list_var_duplicates])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_temp[list_duplicates][list_var_duplicates].sort_values('movie_title')[31:41]\n",
    "df_temp[list_duplicates][list_var_duplicates].sort_values('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords, keywords_roots, keywords_select = keywords_inventory(df, column = 'keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of a sample of keywords that appear in close varieties \n",
    "#------------------------------------------------------------\n",
    "icount = 0\n",
    "for s in keywords_roots.keys():\n",
    "    if len(keywords_roots[s]) > 1: \n",
    "        icount += 1\n",
    "        if icount < 15: print(icount, keywords_roots[s], len(keywords_roots[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_cleaned = replacement_df_keywords(df, keywords_select,\n",
    "                                               roots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of the keywords occurences\n",
    "#----------------------------------\n",
    "keyword_occurences, keywords_count = count_word(df_keywords_cleaned,'keywords',keywords)\n",
    "keyword_occurences[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple of a list of synonyms given by NLTK\n",
    "#---------------------------------------------------\n",
    "mot_cle = 'alien'\n",
    "lemma = get_synonyms(mot_cle)\n",
    "for s in lemma:\n",
    "    print(' \"{:<30}\" in keywords list -> {} {}'.format(s, s in keywords,\n",
    "                                                keywords_count[s] if s in keywords else 0 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_occurences.sort(key = lambda x:x[1], reverse = False)\n",
    "key_count = dict()\n",
    "for s in keyword_occurences:\n",
    "    key_count[s[0]] = s[1]\n",
    "#__________________________________________________________________________\n",
    "# Creation of a dictionary to replace keywords by higher frequency keywords\n",
    "replacement_mot = dict()\n",
    "icount = 0\n",
    "for index, [mot, nb_apparitions] in enumerate(keyword_occurences):\n",
    "    if nb_apparitions > 5: continue  # only the keywords that appear less than 5 times\n",
    "    lemma = get_synonyms(mot)\n",
    "    if len(lemma) == 0: continue     # case of the plurals\n",
    "    #_________________________________________________________________\n",
    "    list_mots = [(s, key_count[s]) for s in lemma \n",
    "                  if test_keyword(s, key_count, key_count[mot])]\n",
    "    list_mots.sort(key = lambda x:(x[1],x[0]), reverse = True)    \n",
    "    if len(list_mots) <= 1: continue       # no replacement\n",
    "    if mot == list_mots[0][0]: continue    # replacement by himself\n",
    "    icount += 1\n",
    "    if  icount < 8:\n",
    "        print('{:<12} -> {:<12} (init: {})'.format(mot, list_mots[0][0], list_mots))    \n",
    "    replacement_mot[mot] = list_mots[0][0]\n",
    "\n",
    "print(90*'_'+'\\n'+'The replacement concerns {}% of the keywords.'\n",
    "      .format(round(len(replacement_mot)/len(keywords)*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 successive replacements\n",
    "#---------------------------\n",
    "print('Keywords that appear both in keys and values:'.upper()+'\\n'+45*'-')\n",
    "icount = 0\n",
    "for s in replacement_mot.values():\n",
    "    if s in replacement_mot.keys():\n",
    "        icount += 1\n",
    "        if icount < 10: print('{:<20} -> {:<20}'.format(s, replacement_mot[s]))\n",
    "\n",
    "for key, value in replacement_mot.items():\n",
    "    if value in replacement_mot.keys():\n",
    "        replacement_mot[key] = replacement_mot[value]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_synonyms = \\\n",
    "            replacement_df_keywords(df_keywords_cleaned, replacement_mot, roots = False)   \n",
    "keywords, keywords_roots, keywords_select = \\\n",
    "            keywords_inventory(df_keywords_synonyms, column = 'keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keyword_occurences, keywords_count = count_word(df_keywords_synonyms,\n",
    "                                                    'keywords',keywords)\n",
    "new_keyword_occurences[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_keywords_occurence = \\\n",
    "    replacement_df_low_frequency_keywords(df_keywords_synonyms, new_keyword_occurences)\n",
    "keywords, keywords_roots, keywords_select = \\\n",
    "    keywords_inventory(df_keywords_occurence, column = 'keywords')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------\n",
    "new_keyword_occurences, keywords_count = count_word(df_keywords_occurence,\n",
    "                                                    'keywords',keywords)\n",
    "new_keyword_occurences[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = find_similarities(df, 0, del_sequels = True, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
